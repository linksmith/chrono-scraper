# Application Settings
PROJECT_NAME="Chrono Scraper"
VERSION="2.0.0"
ENVIRONMENT="development"

# Security
SECRET_KEY="your-secret-key-here"
ACCESS_TOKEN_EXPIRE_MINUTES=11520
EMAIL_RESET_TOKEN_EXPIRE_HOURS=48

# Database
POSTGRES_SERVER="postgres"
POSTGRES_USER="chrono_scraper"
POSTGRES_PASSWORD="chrono_scraper_dev"
POSTGRES_DB="chrono_scraper"
POSTGRES_PORT=5432

# Redis
REDIS_HOST="redis"
REDIS_PORT=6379
REDIS_DB=0

# Celery
CELERY_BROKER_URL="redis://redis:6379/0"
CELERY_RESULT_BACKEND="redis://redis:6379/1"

# Meilisearch
MEILISEARCH_HOST="http://meilisearch:7700"
MEILISEARCH_MASTER_KEY="masterKey_dev"

# Email (Optional)
SMTP_TLS=true
SMTP_PORT=587
SMTP_HOST=""
SMTP_USER=""
SMTP_PASSWORD=""
EMAILS_FROM_EMAIL=""
EMAILS_FROM_NAME=""

# OAuth2 (Optional)
GOOGLE_CLIENT_ID=""
GOOGLE_CLIENT_SECRET=""
GITHUB_CLIENT_ID=""
GITHUB_CLIENT_SECRET=""
OAUTH2_ENABLED=false

# Scraping Settings
DEFAULT_REQUEST_TIMEOUT=30
DEFAULT_REQUESTS_PER_SECOND=1.0
DEFAULT_BURST_SIZE=5
MAX_RETRIES=3
RETRY_DELAY=1.0
USER_AGENT="chrono-scraper/2.0 (research tool)"

# Rate Limiting
ENABLE_RATE_LIMITING=true
GLOBAL_RATE_LIMIT=10.0
DOMAIN_RATE_LIMIT=1.0

# Archive Source Configuration
# Default archive source for new projects (wayback, commoncrawl, auto)
DEFAULT_ARCHIVE_SOURCE="wayback"
# Enable automatic fallback to secondary archives when primary fails
DEFAULT_FALLBACK_ENABLED=true
# Enable intelligent source selection based on URL patterns and availability
ARCHIVE_SOURCE_AUTO_DETECTION=true

# Common Crawl Settings
COMMON_CRAWL_TIMEOUT=240
COMMON_CRAWL_MAX_RETRIES=3
COMMON_CRAWL_MAX_PAGES=10000
COMMON_CRAWL_RATE_LIMIT=2.0

# Archive Fallback Behavior
ARCHIVE_FALLBACK_DELAY=3
ARCHIVE_FALLBACK_STRATEGY="sequential"
ARCHIVE_CIRCUIT_BREAKER_THRESHOLD=5
ARCHIVE_CIRCUIT_BREAKER_RECOVERY_TIME=300

# Archive Performance Settings
ARCHIVE_QUERY_CACHE_TTL=3600
ARCHIVE_CONCURRENT_REQUESTS=3
ARCHIVE_BATCH_SIZE=100
ARCHIVE_GLOBAL_TIMEOUT=300
ARCHIVE_ENABLE_COMPRESSION=true

# DuckDB Analytics Engine Configuration
DUCKDB_DATABASE_PATH="/var/lib/duckdb/chrono_analytics.db"
DUCKDB_MEMORY_LIMIT="4GB"
DUCKDB_WORKER_THREADS=4
DUCKDB_ENABLE_S3=false
DUCKDB_TEMP_DIRECTORY="/tmp/duckdb"
DUCKDB_MAX_MEMORY_PERCENTAGE=60

# Parquet Configuration
PARQUET_COMPRESSION="ZSTD"
PARQUET_ROW_GROUP_SIZE=1000000
PARQUET_PAGE_SIZE=1048576
PARQUET_ENABLE_DICTIONARY=true

# Data Synchronization Settings
DATA_SYNC_BATCH_SIZE=10000
DATA_SYNC_INTERVAL=300
ENABLE_DUAL_WRITE=true
SYNC_RETRY_ATTEMPTS=3
SYNC_RETRY_DELAY=60

# Analytics Query Configuration
ANALYTICS_QUERY_TIMEOUT=30
ANALYTICS_CACHE_TTL=1800
ANALYTICS_MAX_RESULT_SIZE=1000000
ENABLE_QUERY_OPTIMIZATION=true

# S3 Configuration (Optional - for remote Parquet storage)
AWS_ACCESS_KEY_ID=""
AWS_SECRET_ACCESS_KEY=""
AWS_DEFAULT_REGION="us-east-1"
S3_BUCKET_NAME=""
S3_PARQUET_PREFIX="analytics/"

# Intelligent Extraction Settings
INTELLIGENT_EXTRACTION_CONCURRENCY=50
EXTRACTION_CACHE_TTL=3600

# CORS
BACKEND_CORS_ORIGINS=["http://localhost:3000","http://localhost:5173"]

# Superuser
FIRST_SUPERUSER="admin@chrono-scraper.com"
FIRST_SUPERUSER_PASSWORD="changeme"

# Registration
USERS_OPEN_REGISTRATION=true
REQUIRE_EMAIL_VERIFICATION=true